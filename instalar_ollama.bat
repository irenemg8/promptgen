@echo off
echo.
echo ===============================================
echo  INSTALADOR AUTOMATICO DE OLLAMA PARA WINDOWS
echo ===============================================
echo.

REM Verificar si Python estÃ¡ instalado
python --version >nul 2>&1
if %errorlevel% neq 0 (
    echo âŒ Python no estÃ¡ instalado. Instalando...
    echo ğŸ“¥ Descargando Python...
    powershell -Command "Invoke-WebRequest -Uri 'https://www.python.org/ftp/python/3.11.6/python-3.11.6-amd64.exe' -OutFile 'python-installer.exe'"
    echo ğŸš€ Ejecutando instalador de Python...
    python-installer.exe /quiet InstallAllUsers=1 PrependPath=1
    del python-installer.exe
    echo âœ… Python instalado
) else (
    echo âœ… Python ya estÃ¡ instalado
)

REM Verificar si Ollama estÃ¡ instalado
ollama --version >nul 2>&1
if %errorlevel% neq 0 (
    echo.
    echo ğŸ“¦ Ollama no estÃ¡ instalado. Instalando...
    echo ğŸ“¥ Descargando Ollama...
    powershell -Command "Invoke-WebRequest -Uri 'https://ollama.com/download/OllamaSetup.exe' -OutFile 'OllamaSetup.exe'"
    echo ğŸš€ Ejecutando instalador de Ollama...
    echo âš ï¸  IMPORTANTE: Acepta todas las opciones por defecto
    start /wait OllamaSetup.exe
    del OllamaSetup.exe
    echo âœ… Ollama instalado
) else (
    echo âœ… Ollama ya estÃ¡ instalado
)

REM Iniciar servicio de Ollama
echo.
echo ğŸš€ Iniciando servicio de Ollama...
start /B ollama serve
timeout /t 5 /nobreak >nul

REM Verificar si el servicio estÃ¡ corriendo
echo â³ Verificando conexiÃ³n...
timeout /t 3 /nobreak >nul
curl -s http://localhost:11434/api/tags >nul 2>&1
if %errorlevel% neq 0 (
    echo âš ï¸  El servicio tardÃ³ en iniciar. Esperando...
    timeout /t 5 /nobreak >nul
    curl -s http://localhost:11434/api/tags >nul 2>&1
    if %errorlevel% neq 0 (
        echo âŒ Error conectando con Ollama
        echo ğŸ’¡ Intenta ejecutar manualmente: ollama serve
        pause
        exit /b 1
    )
)

echo âœ… Ollama estÃ¡ funcionando correctamente

REM Verificar modelos instalados
echo.
echo ğŸ” Verificando modelos instalados...
ollama list >nul 2>&1
if %errorlevel% neq 0 (
    echo âš ï¸  No se pudieron verificar los modelos
) else (
    echo ğŸ“š Modelos instalados:
    ollama list
)

REM Preguntar si instalar modelo bÃ¡sico
echo.
set /p instalar_modelo="Â¿Quieres instalar el modelo bÃ¡sico llama3.2:1b (1.3GB)? (s/n): "
if /i "%instalar_modelo%"=="s" (
    echo ğŸ“¥ Descargando modelo llama3.2:1b... (esto puede tardar varios minutos)
    ollama pull llama3.2:1b
    if %errorlevel% neq 0 (
        echo âŒ Error descargando modelo
    ) else (
        echo âœ… Modelo llama3.2:1b instalado exitosamente
    )
) else (
    echo â­ï¸  Saltando instalaciÃ³n de modelo
)

REM Probar conexiÃ³n
echo.
echo ğŸ§ª Probando conexiÃ³n final...
curl -s -X POST http://localhost:11434/api/generate -d "{\"model\":\"llama3.2:1b\",\"prompt\":\"Hello\",\"stream\":false}" >nul 2>&1
if %errorlevel% neq 0 (
    echo âš ï¸  No se pudo probar el modelo, pero Ollama estÃ¡ funcionando
) else (
    echo âœ… Prueba exitosa
)

REM Crear script de inicio
echo.
echo ğŸ“ Creando script de inicio...
echo @echo off > start_ollama.bat
echo echo Iniciando Ollama... >> start_ollama.bat
echo ollama serve >> start_ollama.bat
echo pause >> start_ollama.bat
echo âœ… Script creado: start_ollama.bat

echo.
echo ===============================================
echo  ğŸ‰ INSTALACIÃ“N COMPLETADA EXITOSAMENTE!
echo ===============================================
echo.
echo âœ… Ollama estÃ¡ instalado y funcionando
echo ğŸŒ Puedes usar el chat ahora
echo ğŸ“ Para reiniciar Ollama: ejecuta start_ollama.bat
echo.
echo ğŸš€ Para usar el sistema completo:
echo    1. Ejecuta: python simple_api_server.py
echo    2. Ejecuta: npm run dev
echo    3. Visita: http://localhost:3001/chat
echo.
pause 