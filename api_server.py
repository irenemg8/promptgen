# api_server.py - Servidor API Empresarial para PromptGen
import uvicorn
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
import sys
import os
import logging
import time

# Configuraci√≥n de logging empresarial
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# A√±adir el directorio actual al path para importar m√≥dulos empresariales
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.append(current_dir)

# Importar el nuevo sistema empresarial
try:
    from promptgen_enterprise import (
        analyze_prompt_quality_bart,
        get_structural_feedback,
        generate_variations,
        generate_ideas,
        EnterpriseModelManager,
        AdvancedQualityAnalyzer,
        ProgressiveImprovementEngine
    )
    from monitoring_system import get_monitoring_system
    
    logger.info("‚úÖ Sistema empresarial PromptGen cargado exitosamente")
    
    # Inicializar componentes empresariales
    model_manager = EnterpriseModelManager()
    quality_analyzer = AdvancedQualityAnalyzer()
    improvement_engine = ProgressiveImprovementEngine(model_manager, quality_analyzer)
    monitoring = get_monitoring_system()
    
except ImportError as e:
    logger.error(f"‚ùå Error al importar sistema empresarial: {e}")
    # Funciones dummy para que el servidor pueda arrancar
    def analyze_prompt_quality_bart(prompt: str):
        return {"error": "Sistema empresarial no disponible"}
    def get_structural_feedback(prompt: str, model_name: str):
        return {"error": "Sistema empresarial no disponible"}
    def generate_variations(prompt: str, model_name: str, num_variations: int):
        return {"error": "Sistema empresarial no disponible"}
    def generate_ideas(prompt: str, model_name: str, num_ideas: int):
        return {"error": "Sistema empresarial no disponible"}
    monitoring = None

# Importar sistema real como alternativa
try:
    from promptgen_real_system import (
        RealIterativeImprover, RealQualityAnalyzer, RealModelManager,
        improve_iteratively_real, analyze_quality_real
    )
    REAL_SYSTEM_AVAILABLE = True
    logger.info("‚úÖ Sistema real de mejora cargado como alternativa")
    
    # Inicializar sistema real
    real_improver = RealIterativeImprover()
    real_analyzer = RealQualityAnalyzer()
    
except ImportError as e:
    REAL_SYSTEM_AVAILABLE = False
    logger.warning(f"‚ö†Ô∏è Sistema real no disponible: {e}")
    real_improver = None
    real_analyzer = None

app = FastAPI(
    title="PromptGen Enterprise API",
    description="API empresarial para an√°lisis y mejora iterativa de prompts con modelos reales de Hugging Face.",
    version="2.0.0"
)

# Configuraci√≥n de CORS empresarial
origins = [
    "http://localhost",
    "http://localhost:3000",
    "http://127.0.0.1:3000",
    "http://localhost:3001",  # Puerto alternativo
    "https://promptgen.enterprise.com",  # Dominio de producci√≥n
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Modelos Pydantic Empresariales ---

class PromptRequest(BaseModel):
    prompt: str
    
    class Config:
        schema_extra = {
            "example": {
                "prompt": "Quiero crear una p√°gina web para una cafeter√≠a"
            }
        }

class ModelNameRequest(PromptRequest):
    model_name: str = "gpt2"
    
    class Config:
        schema_extra = {
            "example": {
                "prompt": "Desarrollar un sistema de gesti√≥n empresarial",
                "model_name": "gpt2"
            }
        }

class VariationRequest(ModelNameRequest):
    num_variations: int = 3
    
class IdeaRequest(ModelNameRequest):
    num_ideas: int = 3

class IterativeImprovementRequest(BaseModel):
    prompt: str
    model_name: str = "gpt2"
    max_iterations: int = 5
    target_quality: float = 85.0
    
    class Config:
        schema_extra = {
            "example": {
                "prompt": "Crear una aplicaci√≥n m√≥vil",
                "model_name": "gpt2",
                "max_iterations": 3,
                "target_quality": 80.0
            }
        }

# --- Middleware Empresarial de Monitoreo ---

@app.middleware("http")
async def monitoring_middleware(request: Request, call_next):
    """Middleware empresarial para monitoreo de requests"""
    start_time = time.time()
    
    # Registrar inicio de request
    if monitoring:
        monitoring.record_session_activity(str(request.client.host if request.client else "unknown"))
    
    try:
        response = await call_next(request)
        
        # Calcular tiempo de respuesta
        response_time = time.time() - start_time
        
        # Registrar m√©tricas
        if monitoring:
            monitoring.record_request(
                endpoint=str(request.url.path),
                response_time=response_time,
                success=response.status_code < 400
            )
        
        # A√±adir headers de monitoreo
        response.headers["X-Response-Time"] = f"{response_time:.3f}s"
        response.headers["X-Server-Version"] = "PromptGen-Enterprise-2.0.0"
        
        return response
        
    except Exception as e:
        # Registrar error
        response_time = time.time() - start_time
        if monitoring:
            monitoring.record_request(
                endpoint=str(request.url.path),
                response_time=response_time,
                success=False
            )
        
        logger.error(f"‚ùå Error en request {request.url.path}: {e}")
        raise

# --- Endpoints Empresariales ---

@app.post("/api/analyze_quality")
async def api_analyze_quality(request_data: PromptRequest):
    """
    An√°lisis avanzado de calidad del prompt con m√©tricas empresariales.
    
    Utiliza el analizador empresarial que eval√∫a:
    - Completitud
    - Claridad  
    - Especificidad
    - Estructura
    - Coherencia
    - Accionabilidad
    """
    if not request_data.prompt or not request_data.prompt.strip():
        raise HTTPException(status_code=400, detail="El prompt no puede estar vac√≠o.")
    
    try:
        start_time = time.time()
        logger.info(f"üìä Analizando calidad del prompt: {request_data.prompt[:50]}...")
        
        # Usar el sistema real si est√° disponible
        if REAL_SYSTEM_AVAILABLE and real_analyzer:
            logger.info("ü§ñ Usando an√°lisis REAL de calidad")
            result = analyze_quality_real(request_data.prompt)
        else:
            logger.warning("‚ö†Ô∏è Usando an√°lisis empresarial como fallback")
            result = analyze_prompt_quality_bart(request_data.prompt)
        
        # Registrar m√©tricas de an√°lisis
        analysis_time = time.time() - start_time
        if monitoring:
            monitoring._update_performance_metrics(quality_analysis_time=analysis_time)
        
        if result.get("error"):
            raise HTTPException(status_code=500, detail=result.get("error"))
            
        logger.info("‚úÖ An√°lisis de calidad completado")
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Error en an√°lisis de calidad: {e}")
        raise HTTPException(status_code=500, detail=f"Error interno del servidor: {str(e)}")

@app.post("/api/generate_feedback")
async def api_structural_feedback(request_data: ModelNameRequest):
    """
    Genera feedback estructural inteligente basado en an√°lisis de calidad.
    """
    if not request_data.prompt or not request_data.prompt.strip():
        raise HTTPException(status_code=400, detail="El prompt no puede estar vac√≠o.")
        
    try:
        logger.info(f"üí° Generando feedback para: {request_data.prompt[:50]}...")
        result = get_structural_feedback(request_data.prompt, request_data.model_name)
        
        if result.get("error"):
            raise HTTPException(status_code=500, detail=result.get("error"))
            
        logger.info("‚úÖ Feedback generado exitosamente")
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Error generando feedback: {e}")
        raise HTTPException(status_code=500, detail=f"Error interno del servidor: {str(e)}")

@app.post("/api/generate_variations")
async def api_generate_variations(request_data: VariationRequest):
    """
    Genera variaciones mejoradas del prompt usando modelos reales de Hugging Face.
    """
    if not request_data.prompt or not request_data.prompt.strip():
        raise HTTPException(status_code=400, detail="El prompt no puede estar vac√≠o.")
        
    try:
        start_time = time.time()
        logger.info(f"üîÑ Generando {request_data.num_variations} variaciones...")
        
        result = generate_variations(
            request_data.prompt, 
            request_data.model_name, 
            request_data.num_variations
        )
        
        # Registrar uso del modelo
        model_time = time.time() - start_time
        if monitoring:
            monitoring.record_model_usage(request_data.model_name, model_time)
        
        if result.get("error"):
            raise HTTPException(status_code=500, detail=result.get("error"))
            
        logger.info("‚úÖ Variaciones generadas exitosamente")
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Error generando variaciones: {e}")
        raise HTTPException(status_code=500, detail=f"Error interno del servidor: {str(e)}")

@app.post("/api/generate_ideas")
async def api_generate_ideas(request_data: IdeaRequest):
    """
    Genera ideas creativas basadas en el prompt usando modelos reales de Hugging Face.
    """
    if not request_data.prompt or not request_data.prompt.strip():
        raise HTTPException(status_code=400, detail="El prompt no puede estar vac√≠o.")
        
    try:
        start_time = time.time()
        logger.info(f"üí° Generando {request_data.num_ideas} ideas...")
        
        result = generate_ideas(
            request_data.prompt, 
            request_data.model_name, 
            request_data.num_ideas
        )
        
        # Registrar uso del modelo
        model_time = time.time() - start_time
        if monitoring:
            monitoring.record_model_usage(request_data.model_name, model_time)
        
        if result.get("error"):
            raise HTTPException(status_code=500, detail=result.get("error"))
            
        logger.info("‚úÖ Ideas generadas exitosamente")
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Error generando ideas: {e}")
        raise HTTPException(status_code=500, detail=f"Error interno del servidor: {str(e)}")

@app.post("/api/improve_iteratively")
async def api_improve_iteratively(request_data: IterativeImprovementRequest):
    """
    Mejora iterativa empresarial con aprendizaje contextual y m√©tricas avanzadas.
    
    Utiliza el motor de mejora progresiva que:
    - Analiza calidad con 6 m√©tricas empresariales
    - Aplica mejoras inteligentes basadas en deficiencias
    - Aprende de iteraciones anteriores
    - Valida mejoras reales vs regresiones
    """
    if not request_data.prompt or not request_data.prompt.strip():
        raise HTTPException(status_code=400, detail="El prompt no puede estar vac√≠o.")
    
    try:
        start_time = time.time()
        logger.info(f"üöÄ Iniciando mejora iterativa empresarial...")
        logger.info(f"   Prompt: {request_data.prompt[:50]}...")
        logger.info(f"   Modelo: {request_data.model_name}")
        logger.info(f"   Max iteraciones: {request_data.max_iterations}")
        logger.info(f"   Calidad objetivo: {request_data.target_quality}%")
        
        # Usar el sistema real si est√° disponible
        if REAL_SYSTEM_AVAILABLE and real_improver:
            logger.info("ü§ñ Usando sistema REAL de mejora con modelos HuggingFace")
            result = real_improver.improve_prompt_iteratively(
                original_prompt=request_data.prompt,
                model_name=request_data.model_name,
                max_iterations=request_data.max_iterations,
                target_quality=request_data.target_quality
            )
        elif 'improvement_engine' in globals():
            logger.warning("‚ö†Ô∏è Usando sistema empresarial como fallback")
            result = improvement_engine.improve_iteratively(
                prompt=request_data.prompt,
                model_name=request_data.model_name,
                max_iterations=request_data.max_iterations,
                target_quality=request_data.target_quality
            )
        else:
            raise HTTPException(status_code=500, detail="Ning√∫n motor de mejora disponible")
        
        # Registrar m√©tricas de mejora
        total_time = time.time() - start_time
        if monitoring and result.get('iterations'):
            # Calcular mejora de calidad
            iterations = result['iterations']
            if len(iterations) > 0:
                original_quality = iterations[0].get('quality_score', 0)
                final_quality = iterations[-1].get('quality_score', 0)
                monitoring.record_prompt_improvement(original_quality, final_quality)
        
        if monitoring:
            monitoring.record_model_usage(request_data.model_name, total_time)
        
        if result.get("error"):
            raise HTTPException(status_code=500, detail=result.get("error"))
            
        logger.info(f"‚úÖ Mejora iterativa completada en {total_time:.2f}s")
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Error en mejora iterativa: {e}")
        raise HTTPException(status_code=500, detail=f"Error interno del servidor: {str(e)}")

# --- Endpoints de Monitoreo y Observabilidad ---

@app.get("/api/health")
async def health_check():
    """
    Endpoint de health check empresarial con m√©tricas detalladas.
    """
    try:
        health_data = {
            "status": "healthy",
            "timestamp": time.time(),
            "version": "2.0.0-enterprise",
            "components": {
                "model_manager": "operational" if 'model_manager' in globals() else "unavailable",
                "quality_analyzer": "operational" if 'quality_analyzer' in globals() else "unavailable", 
                "improvement_engine": "operational" if 'improvement_engine' in globals() else "unavailable",
                "monitoring_system": "operational" if monitoring else "unavailable"
            }
        }
        
        # A√±adir m√©tricas de monitoreo si est√° disponible
        if monitoring:
            dashboard_data = monitoring.get_dashboard_data()
            health_data.update({
                "system_health": dashboard_data.get("system_health", "unknown"),
                "uptime": dashboard_data.get("uptime", 0),
                "active_alerts": dashboard_data.get("total_alerts", 0),
                "critical_alerts": dashboard_data.get("critical_alerts", 0)
            })
        
        return health_data
        
    except Exception as e:
        logger.error(f"‚ùå Error en health check: {e}")
        return JSONResponse(
            status_code=503,
            content={
                "status": "unhealthy",
                "error": str(e),
                "timestamp": time.time()
            }
        )

@app.get("/api/metrics/dashboard")
async def get_dashboard_metrics():
    """
    Endpoint para obtener m√©tricas del dashboard empresarial.
    """
    if not monitoring:
        raise HTTPException(status_code=503, detail="Sistema de monitoreo no disponible")
    
    try:
        dashboard_data = monitoring.get_dashboard_data()
        return dashboard_data
        
    except Exception as e:
        logger.error(f"‚ùå Error obteniendo m√©tricas de dashboard: {e}")
        raise HTTPException(status_code=500, detail=f"Error interno: {str(e)}")

@app.post("/api/metrics/export")
async def export_metrics():
    """
    Endpoint para exportar m√©tricas hist√≥ricas.
    """
    if not monitoring:
        raise HTTPException(status_code=503, detail="Sistema de monitoreo no disponible")
    
    try:
        timestamp = int(time.time())
        filename = f"promptgen_metrics_{timestamp}.json"
        filepath = os.path.join(current_dir, "exports", filename)
        
        # Crear directorio de exports si no existe
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        
        monitoring.export_metrics(filepath)
        
        return {
            "status": "success",
            "message": "M√©tricas exportadas exitosamente",
            "filename": filename,
            "filepath": filepath
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error exportando m√©tricas: {e}")
        raise HTTPException(status_code=500, detail=f"Error interno: {str(e)}")

@app.get("/api/models")
async def get_available_models():
    """
    Obtiene la lista de modelos disponibles con informaci√≥n detallada.
    """
    try:
        if 'model_manager' not in globals():
            raise HTTPException(status_code=503, detail="Gestor de modelos no disponible")
        
        models_info = {
            "available_models": list(model_manager.model_configs.keys()),
            "model_details": {}
        }
        
        for model_key, config in model_manager.model_configs.items():
            models_info["model_details"][model_key] = {
                "name": config["name"],
                "parameters": config.get("parameters", "Unknown"),
                "type": config.get("type", "causal-lm"),
                "description": config.get("description", "Modelo de lenguaje para generaci√≥n de texto"),
                "loaded": model_key in model_manager.model_cache
            }
        
        return models_info
        
    except Exception as e:
        logger.error(f"‚ùå Error obteniendo modelos disponibles: {e}")
        raise HTTPException(status_code=500, detail=f"Error interno del servidor: {str(e)}")

@app.get("/")
async def root():
    """
    Endpoint ra√≠z con informaci√≥n del sistema empresarial.
    """
    return {
        "message": "PromptGen Enterprise API v2.0.0",
        "description": "Sistema empresarial de mejora iterativa de prompts con IA",
        "features": [
            "An√°lisis avanzado de calidad con 6 m√©tricas",
            "Mejora iterativa con aprendizaje contextual", 
            "Modelos reales de Hugging Face",
            "Sistema de monitoreo empresarial",
            "M√©tricas de rendimiento y negocio",
            "Alertas inteligentes",
            "Dashboard de observabilidad"
        ],
        "endpoints": {
            "health": "/api/health",
            "models": "/api/models", 
            "analyze": "/api/analyze_quality",
            "feedback": "/api/get_feedback",
            "variations": "/api/generate_variations",
            "ideas": "/api/generate_ideas",
            "improve": "/api/improve_iteratively",
            "dashboard": "/api/metrics/dashboard",
            "export": "/api/metrics/export"
        },
        "documentation": "/docs"
    }

# --- Configuraci√≥n de Servidor ---

if __name__ == "__main__":
    logger.info("üöÄ Iniciando PromptGen Enterprise API Server...")
    
    try:
        uvicorn.run(
            "api_server:app",
            host="0.0.0.0",
            port=8000,
            reload=True,
            log_level="info"
        )
    except KeyboardInterrupt:
        logger.info("üõë Servidor detenido por usuario")
        if monitoring:
            monitoring.stop_monitoring()
    except Exception as e:
        logger.error(f"‚ùå Error cr√≠tico del servidor: {e}")
        if monitoring:
            monitoring.stop_monitoring()
        raise 