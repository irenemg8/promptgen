import os
from dotenv import load_dotenv
import torch
from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM, BitsAndBytesConfig
from sentence_transformers import SentenceTransformer, util
import numpy as np
import warnings
import re

# Se eliminan todas las referencias a APIs externas y carga de variables de entorno (dotenv).
# El proyecto ahora se basa exclusivamente en modelos de Hugging Face que no requieren API keys.

# Ignorar advertencias espec√≠ficas de transformers
warnings.filterwarnings("ignore", category=FutureWarning, module="transformers.models.bart.modeling_bart")

# --- Carga de Modelos Locales ---
# Diccionario para cachear los pipelines de modelos locales
local_pipelines = {}
active_local_model_name = None

def get_local_text_generation_pipeline(model_name="gpt2", force_reload=False):
    global active_local_model_name
    
    if model_name in local_pipelines and not force_reload and active_local_model_name == model_name:
        return local_pipelines[model_name]

    print(f"Cargando el modelo local: {model_name}...")
    
    # Liberar memoria de la GPU si hay un modelo cargado
    if active_local_model_name and active_local_model_name in local_pipelines:
        print(f"Liberando memoria del modelo anterior: {active_local_model_name}")
        del local_pipelines[active_local_model_name]
        torch.cuda.empty_cache()

    try:
        tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
        
        # Diferenciar la carga seg√∫n la arquitectura del modelo
        if "t5" in model_name.lower():
            # Modelos T5 son Encoder-Decoder (Seq2Seq)
            model = AutoModelForSeq2SeqLM.from_pretrained(
                model_name,
                trust_remote_code=True
            ).to('cuda' if torch.cuda.is_available() else 'cpu')
            pipe = pipeline("text2text-generation", model=model, tokenizer=tokenizer)
        else:
            # Modelos como GPT-2 o GPT-Neo son Decoder-Only (CausalLM)
            # Para modelos m√°s grandes, usar cuantizaci√≥n para reducir el uso de memoria
            if "7b" in model_name.lower() or "1.3b" in model_name.lower(): # Ampliado para otros tama√±os
                bnb_config = BitsAndBytesConfig(
                    load_in_4bit=True,
                    bnb_4bit_use_double_quant=True,
                    bnb_4bit_quant_type="nf4",
                    bnb_4bit_compute_dtype=torch.bfloat16
                )
                model = AutoModelForCausalLM.from_pretrained(
                    model_name,
                    device_map="auto",
                    quantization_config=bnb_config,
                    trust_remote_code=True
                )
            else: # Modelos m√°s peque√±os no necesitan cuantizaci√≥n obligatoriamente
                model = AutoModelForCausalLM.from_pretrained(
                    model_name,
                    trust_remote_code=True
                ).to('cuda' if torch.cuda.is_available() else 'cpu')

            # Asegurarse de que el token de padding est√° definido
            if tokenizer.pad_token is None:
                tokenizer.pad_token = tokenizer.eos_token
                model.config.pad_token_id = model.config.eos_token_id

            pipe = pipeline("text-generation", model=model, tokenizer=tokenizer)

        local_pipelines[model_name] = pipe
        active_local_model_name = model_name
        
        print(f"Modelo local '{model_name}' cargado exitosamente.")
        return pipe
    except Exception as e:
        print(f"Error cr√≠tico al cargar el modelo local '{model_name}': {e}")
        local_pipelines[model_name] = None
        return None

# Carga del modelo para an√°lisis de calidad (BART)
try:
    print("Cargando modelo de an√°lisis de calidad (BART MNLI)...")
    quality_analyzer_pipeline = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")
    print("Modelo de an√°lisis de calidad cargado.")
except Exception as e:
    print(f"Error al cargar el modelo de an√°lisis de calidad: {e}")
    quality_analyzer_pipeline = None

# Carga del modelo para similitud sem√°ntica (opcional, para palabras clave)
try:
    print("Cargando modelo de similitud sem√°ntica...")
    similarity_model = SentenceTransformer('all-MiniLM-L6-v2')
    print("Modelo de similitud sem√°ntica cargado.")
except Exception as e:
    print(f"Error al cargar el modelo de similitud sem√°ntica: {e}")
    similarity_model = None

# --- L√≥gica de Generaci√≥n y An√°lisis (Refactorizada y Simplificada) ---

def generate_text_dispatcher(model_name, prompt, max_length=150):
    """
    Generador de texto que utiliza exclusivamente modelos locales de Hugging Face.
    """
    pipe = get_local_text_generation_pipeline(model_name)
    if pipe is None:
        return {"error": f"Modelo local '{model_name}' no pudo ser cargado."}

    # El prompt ya viene pre-formateado con ejemplos (few-shot)
    full_prompt = prompt

    try:
        # Par√°metros optimizados para cada tipo de modelo
        if "t5" in model_name.lower():
            # T5 es un modelo seq2seq que funciona mejor con instrucciones directas
            sequences = pipe(
                full_prompt,
                max_length=max_length,
                num_return_sequences=1,
                do_sample=True,
                temperature=0.8,
                top_k=40,
                top_p=0.9
            )
        elif "gpt2" in model_name.lower() or "distilgpt2" in model_name.lower():
            # GPT-2 necesita par√°metros m√°s conservadores
            sequences = pipe(
                full_prompt,
                max_new_tokens=max_length,
                num_return_sequences=1,
                pad_token_id=pipe.tokenizer.pad_token_id,
                eos_token_id=pipe.tokenizer.eos_token_id,
                do_sample=True,
                temperature=0.7,
                top_k=30,
                top_p=0.85,
                repetition_penalty=1.2
            )
        elif "neo" in model_name.lower():
            # GPT-Neo puede manejar mejor creatividad
            sequences = pipe(
                full_prompt,
                max_new_tokens=max_length,
                num_return_sequences=1,
                pad_token_id=pipe.tokenizer.pad_token_id,
                eos_token_id=pipe.tokenizer.eos_token_id,
                do_sample=True,
                temperature=0.75,
                top_k=40,
                top_p=0.9,
                repetition_penalty=1.1
            )
        else:
            # Configuraci√≥n por defecto
            sequences = pipe(
                full_prompt,
                max_new_tokens=max_length,
                num_return_sequences=1,
                eos_token_id=pipe.tokenizer.eos_token_id,
                pad_token_id=pipe.tokenizer.pad_token_id,
                do_sample=True,
                top_k=50,
                top_p=0.95,
                temperature=0.7,
            )
            
        # Limpieza de la salida: quitar el prompt original para obtener solo la respuesta generada
        generated_text = sequences[0]['generated_text']
        
        if generated_text.startswith(full_prompt):
            cleaned_text = generated_text[len(full_prompt):].strip()
        else:
            # Para modelos text2text que no repiten el prompt
            cleaned_text = generated_text.strip()

        return cleaned_text
    except Exception as e:
        return {"error": f"Error durante la generaci√≥n de texto con '{model_name}': {str(e)}"}

# --- Funciones de la API (Endpoint Logic) ---

def analyze_prompt_quality_bart(prompt: str):
    """
    Analiza la calidad de un prompt de manera comprehensiva y proporciona feedback detallado.
    """
    # An√°lisis b√°sico de estructura
    words = prompt.split()
    word_count = len(words)
    
    # Extraer concepto para contexto
    concept = extract_core_concept(prompt)
    project_type = detect_project_type(concept)
    
    # 1. AN√ÅLISIS DE PALABRAS CLAVE
    keywords = extract_enhanced_keywords(prompt)
    
    # 2. AN√ÅLISIS DE COMPLETITUD
    completeness_score, completeness_issues = analyze_completeness(prompt, project_type)
    
    # 3. AN√ÅLISIS DE CLARIDAD
    clarity_score, clarity_issues = analyze_clarity(prompt, word_count)
    
    # 4. AN√ÅLISIS DE ESPECIFICIDAD
    specificity_score, specificity_suggestions = analyze_specificity(prompt, project_type)
    
    # 5. AN√ÅLISIS DE ESTRUCTURA
    structure_score, structure_feedback = analyze_structure(prompt)
    
    # 6. CREAR REPORTE DETALLADO
    report = create_detailed_quality_report(
        prompt, word_count, completeness_score, clarity_score, 
        specificity_score, structure_score, completeness_issues,
        clarity_issues, specificity_suggestions, structure_feedback, project_type
    )
    
    return {
        "quality_report": report,
        "interpreted_keywords": keywords,
        "raw_scores": {
            "completeness": completeness_score,
            "clarity": clarity_score,
            "specificity": specificity_score,
            "structure": structure_score
        }
    }

def extract_enhanced_keywords(prompt: str):
    """
    Extrae palabras clave de manera m√°s inteligente del prompt.
    """
    import re
    
    # Palabras vac√≠as en espa√±ol m√°s completa
    stopwords = {
        'el', 'la', 'de', 'que', 'y', 'a', 'en', 'un', 'una', 'para', 'con', 
        'por', 'los', 'las', 'del', 'al', 'es', 'su', 'se', 'como', 'm√°s',
        'me', 'te', 'le', 'nos', 'os', 'les', 'mi', 'tu', 'si', 'no', 'lo',
        'quiero', 'hacer', 'crear', 'generar', 'ayudar', 'puedes', 'prompt',
        'sobre', 'acerca', 'ay√∫dame', 'necesito', 'gustar√≠a'
    }
    
    # Extraer palabras significativas
    words = re.findall(r'\b[a-z√°√©√≠√≥√∫√±√ºA-Z√Å√â√ç√ì√ö√ë√ú]{3,}\b', prompt.lower())
    significant_words = [w for w in words if w not in stopwords and len(w) > 2]
    
    # Detectar frases importantes (sustantivo + adjetivo/complemento)
    phrases = re.findall(r'\b(?:aplicaci√≥n|p√°gina|sitio|logo|cartel|video|art√≠culo|campa√±a|plan|estrategia|sistema|plataforma)\s+[a-z√°√©√≠√≥√∫√±√º\s]{1,20}(?:para|de|sobre|con)', prompt.lower())
    
    # Combinar palabras individuales y frases
    keywords_list = []
    
    # A√±adir frases importantes primero
    for phrase in phrases[:2]:  # M√°ximo 2 frases
        clean_phrase = re.sub(r'\s+', ' ', phrase.strip())
        if clean_phrase:
            keywords_list.append(clean_phrase)
    
    # A√±adir palabras individuales m√°s relevantes
    word_importance = {}
    for word in significant_words:
        # Dar m√°s peso a palabras t√©cnicas y espec√≠ficas
        weight = 1
        if word in ['dise√±o', 'desarrollo', 'marketing', 'contenido', 'estrategia', 'aplicaci√≥n', 'sistema']:
            weight = 2
        if len(word) > 6:  # Palabras m√°s largas suelen ser m√°s espec√≠ficas
            weight += 1
        word_importance[word] = weight
    
    # Ordenar por importancia y tomar las mejores
    sorted_words = sorted(word_importance.items(), key=lambda x: x[1], reverse=True)
    for word, _ in sorted_words[:4]:  # M√°ximo 4 palabras individuales
        if word not in ' '.join(keywords_list).lower():
            keywords_list.append(word)
    
    return ', '.join(keywords_list) if keywords_list else "proyecto, dise√±o"

def analyze_completeness(prompt: str, project_type: str):
    """
    Analiza qu√© tan completo es el prompt seg√∫n el tipo de proyecto.
    """
    elements_by_type = {
        'dise√±o_grafico': ['estilo', 'color', 'tama√±o', 'formato', 'p√∫blico', 'uso'],
        'web_desarrollo': ['funcionalidad', 'audiencia', 'contenido', 'tecnolog√≠a', 'responsive'],
        'aplicacion_movil': ['plataforma', 'funcionalidad', 'usuarios', 'monetizaci√≥n'],
        'contenido_escrito': ['audiencia', 'tono', 'extensi√≥n', 'prop√≥sito', 'formato'],
        'marketing': ['objetivo', 'audiencia', 'presupuesto', 'canales', 'kpis'],
        'video_multimedia': ['duraci√≥n', 'estilo', 'audiencia', 'plataforma', 'mensaje'],
        'general': ['objetivo', 'audiencia', 'recursos', 'contexto']
    }
    
    expected_elements = elements_by_type.get(project_type, elements_by_type['general'])
    prompt_lower = prompt.lower()
    
    present_elements = []
    missing_elements = []
    
    element_indicators = {
        'estilo': ['estilo', 'dise√±o', 'visual', 'moderno', 'vintage', 'minimalista'],
        'color': ['color', 'colores', 'paleta', 'crom√°tico'],
        'tama√±o': ['tama√±o', 'dimensi√≥n', 'formato', 'resoluci√≥n'],
        'p√∫blico': ['audiencia', 'p√∫blico', 'usuarios', 'clientes', 'target'],
        'funcionalidad': ['funci√≥n', 'caracter√≠stica', 'feature', 'capacidad'],
        'contenido': ['contenido', 'informaci√≥n', 'texto', 'datos'],
        'objetivo': ['objetivo', 'meta', 'prop√≥sito', 'fin'],
        'presupuesto': ['presupuesto', 'costo', 'precio', 'inversi√≥n'],
        'duraci√≥n': ['duraci√≥n', 'tiempo', 'largo', 'minutos']
    }
    
    for element in expected_elements:
        indicators = element_indicators.get(element, [element])
        if any(indicator in prompt_lower for indicator in indicators):
            present_elements.append(element)
        else:
            missing_elements.append(element)
    
    completeness_score = round((len(present_elements) / len(expected_elements)) * 100)
    
    return completeness_score, missing_elements[:3]  # M√°ximo 3 elementos faltantes

def analyze_clarity(prompt: str, word_count: int):
    """
    Analiza la claridad del prompt.
    """
    issues = []
    
    # An√°lisis de longitud
    if word_count < 3:
        issues.append("Prompt demasiado corto")
        clarity_score = 20
    elif word_count < 5:
        issues.append("Necesita m√°s contexto")
        clarity_score = 40
    elif word_count > 25:
        issues.append("Podr√≠a ser m√°s conciso")
        clarity_score = 70
    else:
        clarity_score = 85
    
    # An√°lisis de ambig√ºedad
    vague_words = ['algo', 'cosa', 'tipo', 'bueno', 'bonito', 'interesante', 'creativo']
    vague_count = sum(1 for word in vague_words if word in prompt.lower())
    if vague_count > 0:
        issues.append("Contiene t√©rminos vagos")
        clarity_score -= vague_count * 15
    
    # An√°lisis de especificidad
    specific_indicators = ['espec√≠fico', 'exacto', 'preciso', 'detallado', 'particular']
    if any(indicator in prompt.lower() for indicator in specific_indicators):
        clarity_score += 10
    
    return max(0, min(100, clarity_score)), issues

def analyze_specificity(prompt: str, project_type: str):
    """
    Analiza qu√© tan espec√≠fico es el prompt y sugiere mejoras.
    """
    suggestions = []
    
    # Sugerencias espec√≠ficas por tipo de proyecto
    type_suggestions = {
        'dise√±o_grafico': [
            "Especifica el estilo visual (moderno, vintage, minimalista, etc.)",
            "Define las dimensiones y formato final",
            "Menciona la paleta de colores preferida",
            "Indica el p√∫blico objetivo"
        ],
        'web_desarrollo': [
            "Define las funcionalidades principales",
            "Especifica el tipo de contenido",
            "Menciona la audiencia objetivo",
            "Indica si necesita ser responsive"
        ],
        'aplicacion_movil': [
            "Especifica las plataformas (iOS, Android)",
            "Define las funcionalidades clave",
            "Menciona el tipo de usuarios",
            "Indica el modelo de monetizaci√≥n"
        ],
        'contenido_escrito': [
            "Define la extensi√≥n aproximada",
            "Especifica el tono y estilo",
            "Menciona el p√∫blico objetivo",
            "Indica el prop√≥sito del contenido"
        ],
        'marketing': [
            "Define los objetivos espec√≠ficos",
            "Especifica la audiencia target",
            "Menciona el presupuesto disponible",
            "Indica los canales preferidos"
        ],
        'video_multimedia': [
            "Especifica la duraci√≥n deseada",
            "Define el estilo visual",
            "Menciona la plataforma de distribuci√≥n",
            "Indica el mensaje principal"
        ],
        'general': [
            "Define objetivos espec√≠ficos",
            "Especifica la audiencia",
            "Menciona los recursos disponibles",
            "Indica el contexto de uso"
        ]
    }
    
    project_suggestions = type_suggestions.get(project_type, type_suggestions['general'])
    
    # Verificar qu√© elementos ya est√°n presentes
    prompt_lower = prompt.lower()
    present_elements = 0
    
    checklist = {
        'audiencia': ['audiencia', 'p√∫blico', 'usuarios', 'clientes', 'target'],
        'estilo': ['estilo', 'dise√±o', 'visual', 'tono'],
        'objetivo': ['objetivo', 'prop√≥sito', 'meta', 'fin'],
        'formato': ['formato', 'tama√±o', 'dimensi√≥n', 'extensi√≥n']
    }
    
    for element, indicators in checklist.items():
        if any(indicator in prompt_lower for indicator in indicators):
            present_elements += 1
    
    specificity_score = (present_elements / len(checklist)) * 100
    
    # Seleccionar las 3 sugerencias m√°s relevantes que no est√©n presentes
    final_suggestions = []
    for suggestion in project_suggestions:
        if len(final_suggestions) < 3:
            suggestion_keywords = suggestion.lower()
            if not any(keyword in prompt_lower for keyword in ['audiencia', 'objetivo', 'estilo', 'formato'] if keyword in suggestion_keywords):
                final_suggestions.append(suggestion)
    
    return round(specificity_score), final_suggestions

def analyze_structure(prompt: str):
    """
    Analiza la estructura del prompt.
    """
    feedback = []
    
    # Verificar si tiene estructura b√°sica
    has_action = any(verb in prompt.lower() for verb in ['crear', 'dise√±ar', 'desarrollar', 'hacer', 'generar', 'escribir'])
    has_object = any(noun in prompt.lower() for noun in ['logo', 'web', 'app', 'art√≠culo', 'video', 'campa√±a', 'aplicaci√≥n'])
    has_context = any(prep in prompt.lower() for prep in ['para', 'sobre', 'de', 'con'])
    
    structure_elements = sum([has_action, has_object, has_context])
    structure_score = (structure_elements / 3) * 100
    
    if not has_action:
        feedback.append("Incluye una acci√≥n clara (crear, dise√±ar, desarrollar, etc.)")
    if not has_object:
        feedback.append("Especifica qu√© tipo de elemento necesitas")
    if not has_context:
        feedback.append("A√±ade contexto sobre el prop√≥sito o tema")
    
    if structure_score == 100:
        feedback.append("Estructura bien definida")
    
    return round(structure_score), feedback[:2]  # M√°ximo 2 comentarios

def create_detailed_quality_report(prompt, word_count, completeness_score, clarity_score, 
                                 specificity_score, structure_score, completeness_issues,
                                 clarity_issues, specificity_suggestions, structure_feedback, project_type):
    """
    Crea un reporte detallado de calidad del prompt.
    """
    # Calcular puntuaci√≥n general
    overall_score = round((completeness_score + clarity_score + specificity_score + structure_score) / 4)
    
    # Crear reporte
    report = f"üìä An√°lisis detallado del prompt ({word_count} palabras)\n\n"
    
    # Puntuaci√≥n general con emoji
    if overall_score >= 80:
        report += f"üèÜ Calidad general: {overall_score}% - Excelente\n"
    elif overall_score >= 60:
        report += f"‚úÖ Calidad general: {overall_score}% - Buena\n"
    elif overall_score >= 40:
        report += f"‚ö†Ô∏è Calidad general: {overall_score}% - Mejorable\n"
    else:
        report += f"‚ùå Calidad general: {overall_score}% - Necesita mejoras\n"
    
    report += f"üéØ Tipo de proyecto detectado: {project_type.replace('_', ' ').title()}\n\n"
    
    # An√°lisis detallado
    report += "üìà An√°lisis por categor√≠as:\n"
    report += f"‚Ä¢ Completitud: {completeness_score}%\n"
    report += f"‚Ä¢ Claridad: {clarity_score}%\n"
    report += f"‚Ä¢ Especificidad: {specificity_score}%\n"
    report += f"‚Ä¢ Estructura: {structure_score}%\n\n"
    
    # Recomendaciones espec√≠ficas
    if completeness_issues or clarity_issues or specificity_suggestions or structure_feedback:
        report += "üí° Recomendaciones de mejora:\n"
        
        # Mostrar los problemas m√°s importantes primero
        all_feedback = []
        
        if completeness_issues:
            all_feedback.extend([f"Incluye informaci√≥n sobre: {', '.join(completeness_issues)}"])
        
        if clarity_issues:
            all_feedback.extend(clarity_issues)
            
        if structure_feedback and structure_score < 80:
            all_feedback.extend(structure_feedback)
            
        if specificity_suggestions:
            all_feedback.extend(specificity_suggestions[:2])  # Solo las 2 m√°s importantes
        
        # Mostrar m√°ximo 4 recomendaciones
        for i, feedback in enumerate(all_feedback[:4], 1):
            report += f"{i}. {feedback}\n"
    
    if overall_score >= 80:
        report += "\nüéâ ¬°Tu prompt tiene una calidad excelente!"
    elif overall_score >= 60:
        report += "\nüëç Tu prompt tiene buena calidad, con algunas mejoras ser√° perfecto"
    
    return report

def extract_core_concept(prompt: str):
    """
    Extrae el concepto principal del prompt del usuario, eliminando meta-texto.
    """
    # Limpiar el prompt
    clean_prompt = prompt.lower().strip()
    
    # Remover frases meta como "me puedes generar un prompt" o "quiero"
    meta_phrases = [
        r'me puedes?\s+(?:generar|crear|hacer|ayudar|dar|proporcionar)',
        r'puedes?\s+(?:generar|crear|hacer|ayudar|dar|proporcionar)',
        r'genera?r?\s+un\s+prompt',
        r'crear?\s+un\s+prompt',
        r'prompt\s+que\s+me\s+ayude?',
        r'ay√∫dame\s+a',
        r'que\s+me\s+ayude',
        r'^quiero\s+',  # Nuevo: remover "quiero" al inicio
        r'^necesito\s+',
        r'^me\s+gustar√≠a\s+',
    ]
    
    for pattern in meta_phrases:
        clean_prompt = re.sub(pattern, '', clean_prompt, flags=re.IGNORECASE)
    
    # Patrones m√°s espec√≠ficos y precisos para extraer el concepto central
    patterns = [
        # "dise√±ar un cartel de una pel√≠cula futurista"
        r'(?:dise√±ar|crear|hacer|desarrollar|generar|construir|elaborar|producir)\s+(?:una?|un)?\s*([^?]+?)(?:\?|$)',
        # "cartel de una pel√≠cula futurista" (directo)
        r'^([a-z√°√©√≠√≥√∫√±\s]+(?:de|para|sobre|con)\s+[^?]+?)(?:\?|$)',
        # "sobre inteligencia artificial"
        r'sobre\s+(.+?)(?:\?|$)',
        # "acerca de machine learning"
        r'(?:acerca\s+de|relacionado\s+con)\s+(.+?)(?:\?|$)',
        # Cualquier sustantivo + complemento
        r'^([a-z√°√©√≠√≥√∫√±]+(?:\s+[a-z√°√©√≠√≥√∫√±]+)*(?:\s+de\s+[^?]+)?)(?:\?|$)',
        # Fallback general
        r'^\s*(.+?)(?:\?|$)'
    ]
    
    # Extraer el concepto usando patrones
    for pattern in patterns:
        match = re.search(pattern, clean_prompt.strip(), re.IGNORECASE)
        if match:
            concept = match.group(1).strip()
            
            # Limpiar preposiciones innecesarias al inicio
            concept = re.sub(r'^(a|con|para|de|que|una?|el|la|los|las)\s+', '', concept)
            
            # No cortar en preposiciones que son parte del concepto
            # Solo limpiar palabras sobrantes muy espec√≠ficas al final
            concept = re.sub(r'\s+(que\s+(?:me\s+)?ayude|para\s+(?:mi|el)).*$', '', concept)
            
            if len(concept.split()) >= 1 and len(concept) > 3:  # M√°s flexible
                return concept
    
    # Fallback: tomar palabras significativas sin filtrar demasiado
    words = clean_prompt.split()
    significant_words = [w for w in words if len(w) > 2 and w not in ['crear', 'generar', 'hacer', 'ayude', 'puedes', 'prompt', 'ayudar', 'para', 'que', 'una', 'una']]
    
    if significant_words:
        return ' '.join(significant_words[:6])  # M√°s palabras para preservar contexto
    
    return "proyecto creativo"  # Fallback m√°s gen√©rico

def detect_project_type(concept: str):
    """
    Detecta el tipo de proyecto basado en el concepto para usar templates m√°s espec√≠ficos.
    """
    concept_lower = concept.lower()
    
    # Patrones para diferentes tipos de proyectos
    project_types = {
        'dise√±o_grafico': ['cartel', 'p√≥ster', 'logo', 'logotipo', 'banner', 'flyer', 'folleto', 'portada', 'dise√±o gr√°fico', 'ilustraci√≥n'],
        'web_desarrollo': ['p√°gina web', 'sitio web', 'aplicaci√≥n web', 'website', 'plataforma online', 'portal web'],
        'aplicacion_movil': ['aplicaci√≥n m√≥vil', 'app m√≥vil', 'aplicaci√≥n', 'app', 'm√≥vil'],
        'contenido_escrito': ['art√≠culo', 'blog', 'ensayo', 'libro', 'novela', 'cuento', 'historia', 'texto', 'redacci√≥n'],
        'video_multimedia': ['video', 'pel√≠cula', 'documental', 'animaci√≥n', 'cortometraje', 'trailer'],
        'marketing': ['campa√±a', 'marketing', 'publicidad', 'anuncio', 'promoci√≥n', 'estrategia comercial'],
        'educacion': ['curso', 'tutorial', 'gu√≠a', 'manual', 'lecci√≥n', 'capacitaci√≥n', 'entrenamiento'],
        'evento': ['evento', 'conferencia', 'seminario', 'taller', 'workshop', 'presentaci√≥n'],
        'negocio': ['plan de negocio', 'startup', 'empresa', 'emprendimiento', 'proyecto empresarial'],
        'juego': ['juego', 'videojuego', 'game', 'aplicaci√≥n de juego']
    }
    
    for project_type, keywords in project_types.items():
        if any(keyword in concept_lower for keyword in keywords):
            return project_type
    
    return 'general'  # Tipo gen√©rico para proyectos no clasificados

def generate_adaptive_fallback(concept: str, task: str):
    """
    Genera respuestas de respaldo adaptativas basadas en el tipo de proyecto detectado.
    """
    project_type = detect_project_type(concept)
    
    if task == "improve":
        templates_by_type = {
            'dise√±o_grafico': [
                f"Dise√±a un {concept} impactante y profesional, incluyendo composici√≥n visual llamativa, tipograf√≠a creativa, paleta de colores atractiva y elementos gr√°ficos modernos",
                f"Crea un {concept} con estilo visual √∫nico, incorporando tendencias de dise√±o actuales, jerarqu√≠a visual clara y elementos que capten la atenci√≥n del p√∫blico objetivo",
                f"Desarrolla un {concept} memorable que combine creatividad y funcionalidad, con alta resoluci√≥n, formato optimizado para impresi√≥n y elementos visuales cohesivos"
            ],
            'web_desarrollo': [
                f"Desarrolla una {concept} completa y profesional, incluyendo dise√±o moderno, contenido detallado, funcionalidades interactivas y optimizaci√≥n para dispositivos m√≥viles",
                f"Crea una {concept} estructurada con secciones claramente definidas, navegaci√≥n intuitiva, contenido de calidad y elementos visuales atractivos",
                f"Dise√±a una {concept} que incluya informaci√≥n detallada, galer√≠a de im√°genes, testimonios de usuarios y formularios de contacto funcionales"
            ],
            'aplicacion_movil': [
                f"Desarrolla una {concept} innovadora con interfaz intuitiva, experiencia de usuario fluida, funcionalidades √∫tiles y compatibilidad multiplataforma",
                f"Crea una {concept} que incluya dise√±o responsive, navegaci√≥n simple, notificaciones push y integraci√≥n con servicios populares",
                f"Dise√±a una {concept} con arquitectura escalable, rendimiento optimizado, seguridad robusta y caracter√≠sticas que resuelvan problemas reales"
            ],
            'contenido_escrito': [
                f"Redacta un {concept} cautivador y bien estructurado, con investigaci√≥n profunda, estilo narrativo envolvente y contenido original de alta calidad",
                f"Crea un {concept} informativo que incluya introducci√≥n impactante, desarrollo l√≥gico de ideas, ejemplos relevantes y conclusiones s√≥lidas",
                f"Desarrolla un {concept} √∫nico con enfoque espec√≠fico, fuentes confiables, lenguaje apropiado para la audiencia y formato atractivo"
            ],
            'video_multimedia': [
                f"Produce un {concept} visualmente impresionante con narrativa convincente, efectos visuales de calidad, audio profesional y edici√≥n din√°mica",
                f"Crea un {concept} que combine storytelling efectivo, cinematograf√≠a atractiva, banda sonora adecuada y ritmo envolvente",
                f"Desarrolla un {concept} memorable con concepto original, personajes interesantes, mensaje claro y producci√≥n de alta calidad"
            ],
            'marketing': [
                f"Dise√±a una {concept} estrat√©gica con investigaci√≥n de mercado, targeting preciso, mensajes persuasivos y canales de distribuci√≥n efectivos",
                f"Crea una {concept} innovadora que incluya an√°lisis de competencia, propuesta de valor √∫nica, creatividad publicitaria y m√©tricas de √©xito",
                f"Desarrolla una {concept} integral con objetivos claros, presupuesto optimizado, cronograma realista y estrategias de engagement"
            ],
            'educacion': [
                f"Desarrolla un {concept} did√°ctico y completo con objetivos de aprendizaje claros, metodolog√≠a interactiva, recursos variados y evaluaciones efectivas",
                f"Crea un {concept} estructurado que incluya contenido progresivo, ejercicios pr√°cticos, ejemplos reales y herramientas de seguimiento",
                f"Dise√±a un {concept} engaging con formato multimedia, actividades participativas, feedback continuo y adaptaci√≥n a diferentes estilos de aprendizaje"
            ],
            'evento': [
                f"Organiza un {concept} memorable con programa atractivo, speakers relevantes, log√≠stica impecable y experiencia participativa √∫nica",
                f"Planifica un {concept} exitoso que incluya objetivos claros, audiencia definida, contenido valioso y networking efectivo",
                f"Dise√±a un {concept} impactante con formato innovador, tecnolog√≠a integrada, engagement del p√∫blico y seguimiento post-evento"
            ],
            'negocio': [
                f"Desarrolla un {concept} s√≥lido con an√°lisis de mercado, modelo de negocio viable, estrategia financiera y plan de crecimiento escalable",
                f"Crea un {concept} innovador que incluya propuesta de valor diferenciada, an√°lisis de competencia, equipo competente y proyecciones realistas",
                f"Dise√±a un {concept} estrat√©gico con validaci√≥n de mercado, recursos necesarios, cronograma de implementaci√≥n y m√©tricas de √©xito"
            ],
            'juego': [
                f"Desarrolla un {concept} adictivo con mec√°nicas innovadoras, historia envolvente, gr√°ficos atractivos y experiencia de usuario excepcional",
                f"Crea un {concept} divertido que incluya gameplay balanceado, progresi√≥n satisfactoria, elementos sociales y rejugabilidad alta",
                f"Dise√±a un {concept} memorable con concepto original, controles intuitivos, desaf√≠os graduales y sistema de recompensas motivador"
            ],
            'general': [
                f"Desarrolla un {concept} excepcional y profesional, incorporando las mejores pr√°cticas de la industria, innovaci√≥n creativa y atenci√≥n al detalle",
                f"Crea un {concept} √∫nico y de alta calidad que se destaque por su originalidad, funcionalidad y impacto en la audiencia objetivo",
                f"Dise√±a un {concept} completo que combine creatividad, t√©cnica profesional y enfoque estrat√©gico para obtener resultados sobresalientes"
            ]
        }
        return templates_by_type.get(project_type, templates_by_type['general'])
    
    elif task == "feedback":
        feedback_by_type = {
            'dise√±o_grafico': [
                f"Define el estilo visual y la est√©tica deseada para el {concept}",
                f"Especifica las dimensiones, formato y uso final del dise√±o",
                f"Incluye refer√™ncias visuales o inspiraciones estil√≠sticas",
                f"Considera el p√∫blico objetivo y el mensaje que quieres transmitir"
            ],
            'web_desarrollo': [
                f"Especifica el p√∫blico objetivo para la {concept}",
                f"Define las funcionalidades principales que necesitas",
                f"Incluye el tipo de contenido y estructura deseada",
                f"Considera la experiencia de usuario y accesibilidad"
            ],
            'aplicacion_movil': [
                f"Define las funcionalidades principales de la {concept}",
                f"Especifica las plataformas objetivo (iOS, Android, etc.)",
                f"Incluye el tipo de usuarios y sus necesidades",
                f"Considera la monetizaci√≥n y modelo de negocio"
            ],
            'contenido_escrito': [
                f"Especifica el p√∫blico objetivo y tono deseado",
                f"Define la extensi√≥n y formato del {concept}",
                f"Incluye los temas principales a cubrir",
                f"Considera el prop√≥sito y objetivos del contenido"
            ],
            'video_multimedia': [
                f"Define el estilo visual y duraci√≥n del {concept}",
                f"Especifica el p√∫blico objetivo y plataforma de distribuci√≥n",
                f"Incluye el mensaje principal y tono narrativo",
                f"Considera el presupuesto y recursos disponibles"
            ],
            'marketing': [
                f"Define el p√∫blico objetivo y segmentaci√≥n",
                f"Especifica los objetivos y KPIs de la {concept}",
                f"Incluye el presupuesto y canales preferidos",
                f"Considera el timing y duraci√≥n de la campa√±a"
            ],
            'educacion': [
                f"Define el p√∫blico objetivo y nivel de conocimiento",
                f"Especifica los objetivos de aprendizaje del {concept}",
                f"Incluye la metodolog√≠a y formato preferido",
                f"Considera la duraci√≥n y recursos necesarios"
            ],
            'evento': [
                f"Define el p√∫blico objetivo y n√∫mero de asistentes",
                f"Especifica los objetivos y tipo de {concept}",
                f"Incluye el presupuesto y ubicaci√≥n preferida",
                f"Considera la fecha, duraci√≥n y log√≠stica necesaria"
            ],
            'negocio': [
                f"Define el mercado objetivo y propuesta de valor",
                f"Especifica el modelo de negocio del {concept}",
                f"Incluye el an√°lisis de competencia y diferenciaci√≥n",
                f"Considera los recursos y capital necesario"
            ],
            'juego': [
                f"Define el g√©nero y plataforma objetivo del {concept}",
                f"Especifica las mec√°nicas principales de gameplay",
                f"Incluye el p√∫blico objetivo y rating",
                f"Considera el estilo visual y tem√°tica del juego"
            ],
            'general': [
                f"Define los objetivos principales del {concept}",
                f"Especifica el p√∫blico objetivo y sus necesidades",
                f"Incluye los recursos y limitaciones disponibles",
                f"Considera el contexto y prop√≥sito del proyecto"
            ]
        }
        return feedback_by_type.get(project_type, feedback_by_type['general'])
    
    elif task == "ideas":
        ideas_by_type = {
            'dise√±o_grafico': [
                f"Crear una serie de variaciones estil√≠sticas del {concept}",
                f"Desarrollar una gu√≠a de estilo y elementos gr√°ficos complementarios",
                f"Dise√±ar adaptaciones del concepto para diferentes formatos y medios",
                f"Producir un mockup realista mostrando el {concept} en contexto",
                f"Elaborar un proceso creativo documentado del desarrollo del dise√±o"
            ],
            'web_desarrollo': [
                f"Crear un prototipo interactivo de la {concept}",
                f"Desarrollar una estrategia de contenido y SEO",
                f"Dise√±ar un sistema de anal√≠ticas y m√©tricas",
                f"Implementar funcionalidades de accesibilidad avanzadas",
                f"Crear una versi√≥n m√≥vil optimizada"
            ],
            'aplicacion_movil': [
                f"Desarrollar un MVP (Producto M√≠nimo Viable) de la {concept}",
                f"Crear wireframes y prototipos de la interfaz",
                f"Dise√±ar un plan de testing con usuarios reales",
                f"Implementar un sistema de analytics y feedback",
                f"Elaborar una estrategia de lanzamiento en app stores"
            ],
            'contenido_escrito': [
                f"Crear un plan editorial completo para el {concept}",
                f"Desarrollar una serie de contenidos relacionados",
                f"Dise√±ar una estrategia de distribuci√≥n y promoci√≥n",
                f"Implementar SEO y optimizaci√≥n para buscadores",
                f"Crear formatos multimedia complementarios"
            ],
            'video_multimedia': [
                f"Desarrollar un storyboard detallado del {concept}",
                f"Crear un plan de producci√≥n y cronograma",
                f"Dise√±ar una estrategia de distribuci√≥n multiplataforma",
                f"Implementar elementos interactivos o de realidad aumentada",
                f"Producir contenido adicional (behind the scenes, extras)"
            ],
            'marketing': [
                f"Desarrollar una estrategia de marketing digital integral",
                f"Crear contenido viral y campa√±as en redes sociales",
                f"Dise√±ar un sistema de m√©tricas y ROI",
                f"Implementar marketing automation y segmentaci√≥n",
                f"Elaborar partnerships y colaboraciones estrat√©gicas"
            ],
            'educacion': [
                f"Crear materiales de apoyo interactivos para el {concept}",
                f"Desarrollar evaluaciones y sistemas de certificaci√≥n",
                f"Dise√±ar una comunidad de aprendizaje online",
                f"Implementar gamificaci√≥n y elementos motivacionales",
                f"Elaborar programas de mentor√≠a y seguimiento"
            ],
            'evento': [
                f"Crear una experiencia digital complementaria al {concept}",
                f"Desarrollar un programa de networking estructurado",
                f"Dise√±ar actividades interactivas y workshops",
                f"Implementar tecnolog√≠a para engagement en tiempo real",
                f"Elaborar un plan de seguimiento post-evento"
            ],
            'negocio': [
                f"Desarrollar un plan de validaci√≥n de mercado",
                f"Crear prototipos y productos m√≠nimos viables",
                f"Dise√±ar una estrategia de financiaci√≥n y investment",
                f"Implementar sistemas de control y m√©tricas",
                f"Elaborar un plan de escalabilidad y crecimiento"
            ],
            'juego': [
                f"Crear un documento de dise√±o de juego completo",
                f"Desarrollar un prototipo jugable y mec√°nicas b√°sicas",
                f"Dise√±ar la progresi√≥n del jugador y sistema de recompensas",
                f"Implementar elementos multijugador o sociales",
                f"Elaborar una estrategia de monetizaci√≥n √©tica"
            ],
            'general': [
                f"Crear una gu√≠a completa de mejores pr√°cticas para {concept}",
                f"Desarrollar un tutorial paso a paso para implementar {concept}",
                f"Dise√±ar una estrategia de contenido y comunicaci√≥n",
                f"Implementar herramientas de medici√≥n y an√°lisis",
                f"Elaborar un plan de mejora continua y evoluci√≥n"
            ]
        }
        return ideas_by_type.get(project_type, ideas_by_type['general'])[:5]  # L√≠mite de 5 ideas
    
    else:
        return [f"Mejora la descripci√≥n de {concept} con m√°s detalles espec√≠ficos"]

def generate_smart_fallback(concept: str, task: str):
    """
    Genera respuestas de respaldo inteligentes basadas en el concepto extra√≠do.
    DEPRECATED: Usar generate_adaptive_fallback en su lugar.
    """
    return generate_adaptive_fallback(concept, task)

def is_coherent_spanish(text: str, min_words: int = 3):
    """
    Verifica si el texto es coherente y est√° en espa√±ol.
    """
    if not text or len(text.strip()) < 10:
        return False
    
    words = text.split()
    if len(words) < min_words:
        return False
    
    # Verificar que no est√© en ingl√©s
    english_indicators = ['the', 'and', 'or', 'but', 'with', 'from', 'they', 'this', 'that', 'have', 'been', 'will', 'would', 'could', 'should']
    english_count = sum(1 for word in words if word.lower() in english_indicators)
    if english_count > len(words) * 0.2:  # M√°s del 20% en ingl√©s
        return False
    
    # Verificar que no sea repetitivo
    unique_words = set(words)
    if len(unique_words) < len(words) * 0.6:  # Menos del 60% de palabras √∫nicas
        return False
    
    # Verificar que tenga estructura b√°sica de oraci√≥n
    if not any(char in text for char in '.,!?'):
        # Si no tiene puntuaci√≥n, verificar que al menos parezca una oraci√≥n
        if not re.search(r'\b(el|la|un|una|de|para|con|en|que|como|sobre)\b', text.lower()):
            return False
    
    return True

def get_model_specific_prompt(base_prompt: str, model_name: str, task: str):
    """
    Genera prompts optimizados para cada modelo seg√∫n la tarea.
    """
    # Extraer el concepto principal
    concept = extract_core_concept(base_prompt)
    
    if "t5" in model_name.lower():
        # T5 funciona mejor con tareas estructuradas en ingl√©s pero podemos forzar espa√±ol
        if task == "improve":
            return f"paraphrase in Spanish with more details: Create a detailed {concept}"
        elif task == "feedback":
            return f"analyze in Spanish: What can be improved about {concept}"
        elif task == "ideas":
            return f"generate ideas in Spanish for: {concept}"
    
    elif "gpt2" in model_name.lower() or "distilgpt2" in model_name.lower():
        # GPT-2 con ejemplos muy espec√≠ficos en espa√±ol
        if task == "improve":
            return f"""Ejemplo 1:
Concepto: p√°gina sobre perros
Versi√≥n mejorada: Desarrolla una p√°gina web completa sobre razas caninas, incluyendo fichas detalladas de cada raza, consejos de cuidado, galer√≠a fotogr√°fica y directorio de veterinarios especializados

Ejemplo 2:
Concepto: tienda online
Versi√≥n mejorada: Crea una tienda online moderna con cat√°logo de productos, carrito de compras, sistema de pagos seguro, rese√±as de clientes y soporte en tiempo real

Concepto: {concept}
Versi√≥n mejorada:"""
        
        elif task == "feedback":
            return f"""Para mejorar '{concept}', considera estos aspectos:
1. P√∫blico objetivo espec√≠fico
2."""
        
        elif task == "ideas":
            return f"""Ideas para desarrollar '{concept}':
1. Tutorial interactivo paso a paso
2."""
    
    elif "neo" in model_name.lower():
        # GPT-Neo con instrucciones claras en espa√±ol
        if task == "improve":
            return f"""Instrucci√≥n: Reescribe la siguiente idea de manera m√°s detallada y profesional.

Idea original: {concept}

Versi√≥n mejorada y detallada:"""
        
        elif task == "feedback":
            return f"""Analiza qu√© se puede mejorar en esta idea: '{concept}'

Sugerencias de mejora:
-"""
        
        elif task == "ideas":
            return f"""Genera 3 ideas creativas relacionadas con: '{concept}'

Ideas:
1."""
    
    # Default con concepto extra√≠do
    return f"Mejora esta idea: {concept}"

def clean_generated_output(text: str, model_name: str, task: str, original_concept: str):
    """
    Limpia y valida la salida generada seg√∫n el modelo y la tarea.
    """
    if not text:
        return ""
    
    # Eliminar l√≠neas vac√≠as y espacios extra
    lines = [line.strip() for line in text.split('\n') if line.strip()]
    
    # Verificar coherencia en espa√±ol
    full_text = " ".join(lines)
    
    if not is_coherent_spanish(full_text):
        # Si no es coherente, usar fallback adaptativo
        fallbacks = generate_adaptive_fallback(original_concept, task)
        if task == "feedback":
            return "\n".join([f"- {fb}" for fb in fallbacks])
        return fallbacks[0] if fallbacks else f"Desarrolla {original_concept} con m√°s detalles espec√≠ficos"
    
    # Limpieza espec√≠fica por modelo y tarea
    if "gpt2" in model_name.lower() or "distilgpt2" in model_name.lower():
        if task == "improve":
            # Buscar la l√≠nea con la mejora
            for line in lines:
                if (len(line.split()) > 8 and 
                    not line.lower().startswith(('ejemplo', 'concepto', 'versi√≥n', 'idea')) and
                    any(verb in line.lower() for verb in ['desarrolla', 'crea', 'dise√±a', 'incluye', 'contiene'])):
                    return line
        
        elif task == "feedback":
            feedback_lines = []
            for line in lines:
                if (line and len(line.split()) > 3 and
                    not line.lower().startswith(('para', 'considera', 'aspectos'))):
                    if not line.startswith('-'):
                        line = f"- {line}"
                    feedback_lines.append(line)
            return "\n".join(feedback_lines[:4]) if feedback_lines else "\n".join([f"- {fb}" for fb in generate_adaptive_fallback(original_concept, "feedback")])
        
        elif task == "ideas":
            ideas = []
            for line in lines:
                if (line and len(line.split()) > 4 and
                    not line.lower().startswith(('ideas', 'para', 'desarrollar'))):
                    clean_line = re.sub(r'^\d+\.?\s*', '', line)
                    ideas.append(clean_line)
            return ideas[:3] if ideas else generate_adaptive_fallback(original_concept, "ideas")[:3]
    
    elif "t5" in model_name.lower():
        # T5 devuelve respuestas m√°s directas
        if task == "improve":
            result = " ".join(lines)
            if len(result.split()) < 8:
                return generate_adaptive_fallback(original_concept, "improve")[0]
            return result
        elif task in ["feedback", "ideas"]:
            return " ".join(lines) if lines else generate_adaptive_fallback(original_concept, task)[0]
    
    elif "neo" in model_name.lower():
        if task == "improve":
            # Buscar l√≠neas que parezcan mejoras
            for line in lines:
                if (len(line.split()) > 10 and
                    any(verb in line.lower() for verb in ['desarrolla', 'crea', 'dise√±a', 'implementa', 'incluye'])):
                    return line
        
        elif task == "feedback":
            feedback = []
            for line in lines:
                if (line and len(line.split()) > 3 and
                    not any(skip in line.lower() for skip in ['analiza', 'sugerencias', 'mejora:'])):
                    if not line.startswith('-'):
                        line = f"- {line}"
                    feedback.append(line)
            return "\n".join(feedback[:4]) if feedback else "\n".join([f"- {fb}" for fb in generate_adaptive_fallback(original_concept, "feedback")])
        
        elif task == "ideas":
            ideas = []
            for line in lines:
                if (line and len(line.split()) > 4 and
                    not any(skip in line.lower() for skip in ['genera', 'ideas:', 'relacionadas'])):
                    clean_line = re.sub(r'^\d+\.?\s*', '', line)
                    ideas.append(clean_line)
            return ideas[:3] if ideas else generate_adaptive_fallback(original_concept, "ideas")[:3]
    
    # Fallback general
    if task == "improve":
        return generate_adaptive_fallback(original_concept, "improve")[0]
    elif task == "feedback":
        return "\n".join([f"- {fb}" for fb in generate_adaptive_fallback(original_concept, "feedback")])
    elif task == "ideas":
        return generate_adaptive_fallback(original_concept, "ideas")[:3]
    
    return full_text

def get_structural_feedback(prompt: str, model_name: str = "gpt2"):
    """
    Genera feedback sobre la estructura y claridad de un prompt usando un modelo local.
    """
    concept = extract_core_concept(prompt)
    optimized_prompt = get_model_specific_prompt(prompt, model_name, "feedback")
    
    feedback = generate_text_dispatcher(model_name, optimized_prompt, max_length=120)
    if isinstance(feedback, dict) and 'error' in feedback:
        # Usar fallback inteligente
        fallback_feedback = generate_adaptive_fallback(concept, "feedback")
        return {"feedback": "\n".join([f"- {fb}" for fb in fallback_feedback])}
    
    # Limpiar y estructurar el feedback
    cleaned_feedback = clean_generated_output(feedback, model_name, "feedback", concept)
    
    # Validar que el feedback sea √∫til
    if not cleaned_feedback or len(cleaned_feedback.split()) < 10:
        fallback_feedback = generate_adaptive_fallback(concept, "feedback")
        cleaned_feedback = "\n".join([f"- {fb}" for fb in fallback_feedback])
    
    return {"feedback": cleaned_feedback}

def generate_variations(prompt: str, model_name: str = "gpt2", num_variations: int = 3):
    """
    Genera variaciones de un prompt usando un modelo local.
    """
    concept = extract_core_concept(prompt)
    variations = []
    
    if "gpt2" in model_name.lower() or "distilgpt2" in model_name.lower():
        # Para GPT-2, intentar generar una vez con few-shot
        optimized_prompt = get_model_specific_prompt(prompt, model_name, "improve")
        
        response_text = generate_text_dispatcher(model_name, optimized_prompt, max_length=100)
        
        if (not isinstance(response_text, dict) and 
            response_text and 
            is_coherent_spanish(response_text)):
            
            cleaned = clean_generated_output(response_text, model_name, "improve", concept)
            if cleaned and len(cleaned.split()) > 8:
                variations.append(cleaned)
        
        # Completar con fallbacks inteligentes
        fallbacks = generate_adaptive_fallback(concept, "improve")
        while len(variations) < num_variations:
            idx = len(variations)
            if idx < len(fallbacks):
                variations.append(fallbacks[idx])
            else:
                variations.append(f"Desarrolla {concept} de manera {['profesional', 'creativa', 'detallada'][idx % 3]}")
    
    elif "t5" in model_name.lower():
        # T5 con diferentes enfoques
        approaches = ["detailed", "professional", "creative"]
        for i in range(num_variations):
            task_prompt = f"paraphrase in Spanish with {approaches[i % len(approaches)]} style: Create {concept}"
            response_text = generate_text_dispatcher(model_name, task_prompt, max_length=80)
            
            if (not isinstance(response_text, dict) and 
                response_text and 
                is_coherent_spanish(response_text)):
                
                cleaned = clean_generated_output(response_text, model_name, "improve", concept)
                variations.append(cleaned if cleaned else generate_adaptive_fallback(concept, "improve")[0])
            else:
                variations.append(generate_adaptive_fallback(concept, "improve")[i % 3])
    
    else:
        # GPT-Neo y otros
        optimized_prompt = get_model_specific_prompt(prompt, model_name, "improve")
        response_text = generate_text_dispatcher(model_name, optimized_prompt, max_length=120)
        
        if (not isinstance(response_text, dict) and 
            response_text and 
            is_coherent_spanish(response_text)):
            
            cleaned = clean_generated_output(response_text, model_name, "improve", concept)
            if cleaned:
                variations.append(cleaned)
        
        # Completar con fallbacks
        fallbacks = generate_adaptive_fallback(concept, "improve")
        while len(variations) < num_variations:
            idx = len(variations)
            variations.append(fallbacks[idx % len(fallbacks)])
    
    # Asegurar que todas las variaciones sean √∫nicas y v√°lidas
    unique_variations = []
    seen = set()
    for var in variations:
        if var and var not in seen and len(var.split()) > 5:
            seen.add(var)
            unique_variations.append(var)
    
    # Completar si es necesario
    fallbacks = generate_adaptive_fallback(concept, "improve")
    while len(unique_variations) < num_variations:
        idx = len(unique_variations)
        fallback = fallbacks[idx % len(fallbacks)]
        if fallback not in seen:
            unique_variations.append(fallback)
            seen.add(fallback)
    
    return {"variations": unique_variations[:num_variations]}

def generate_ideas(prompt: str, model_name: str = "gpt2", num_ideas: int = 3):
    """
    Genera ideas basadas en un prompt usando un modelo local.
    """
    concept = extract_core_concept(prompt)
    ideas = []
    
    if "gpt2" in model_name.lower() or "distilgpt2" in model_name.lower():
        # Intentar con el modelo
        optimized_prompt = get_model_specific_prompt(prompt, model_name, "ideas")
        response_text = generate_text_dispatcher(model_name, optimized_prompt, max_length=150)
        
        if (not isinstance(response_text, dict) and 
            response_text and 
            is_coherent_spanish(response_text)):
            
            extracted_ideas = clean_generated_output(response_text, model_name, "ideas", concept)
            if isinstance(extracted_ideas, list):
                ideas.extend(extracted_ideas[:num_ideas])
        
        # Completar con templates inteligentes
        smart_ideas = generate_adaptive_fallback(concept, "ideas")
        while len(ideas) < num_ideas:
            idx = len(ideas)
            ideas.append(smart_ideas[idx % len(smart_ideas)])
    
    elif "t5" in model_name.lower():
        # T5 con diferentes enfoques
        approaches = ["tutorial", "guide", "tool", "resource", "strategy"]
        for i in range(num_ideas):
            approach = approaches[i % len(approaches)]
            task_prompt = f"generate idea in Spanish: {approach} for {concept}"
            response_text = generate_text_dispatcher(model_name, task_prompt, max_length=60)
            
            if (not isinstance(response_text, dict) and 
                response_text and 
                is_coherent_spanish(response_text)):
                
                cleaned = response_text.strip()
                ideas.append(f"Crear {cleaned}" if not cleaned.lower().startswith('crear') else cleaned)
            else:
                smart_ideas = generate_adaptive_fallback(concept, "ideas")
                ideas.append(smart_ideas[i % len(smart_ideas)])
    
    else:
        # Otros modelos
        optimized_prompt = get_model_specific_prompt(prompt, model_name, "ideas")
        response_text = generate_text_dispatcher(model_name, optimized_prompt, max_length=150)
        
        if (not isinstance(response_text, dict) and 
            response_text and 
            is_coherent_spanish(response_text)):
            
            extracted_ideas = clean_generated_output(response_text, model_name, "ideas", concept)
            if isinstance(extracted_ideas, list):
                ideas.extend(extracted_ideas[:num_ideas])
        
        # Completar con templates
        smart_ideas = generate_smart_fallback(concept, "ideas")
        while len(ideas) < num_ideas:
            idx = len(ideas)
            ideas.append(smart_ideas[idx % len(smart_ideas)])
    
    # Formatear y limpiar ideas finales
    formatted_ideas = []
    for i, idea in enumerate(ideas[:num_ideas]):
        # Limpiar numeraci√≥n y formatear
        clean_idea = re.sub(r'^\d+\.?\s*[-\s]*', '', str(idea)).strip()
        if clean_idea and len(clean_idea.split()) > 2:
            formatted_ideas.append(clean_idea)
    
    # Asegurar que tengamos suficientes ideas
    smart_fallbacks = generate_smart_fallback(concept, "ideas")
    while len(formatted_ideas) < num_ideas:
        idx = len(formatted_ideas)
        formatted_ideas.append(smart_fallbacks[idx % len(smart_fallbacks)])
    
    return {"ideas": formatted_ideas[:num_ideas]}

def main():
    print("M√≥dulo promptgen_app cargado. Funciones listas para ser usadas por el servidor API.")
    # Prueba r√°pida opcional
    # test_model = "gpt2" # o "google-t5/t5-small"
    # test_prompt = "crea una imagen de un astronauta montando un caballo en marte"
    # print(f"\n--- Probando Feedback con {test_model} ---")
    # print(get_structural_feedback(test_prompt, model_name=test_model))
    # print(f"\n--- Probando Variaciones con {test_model} ---")
    # print(generate_variations(test_prompt, model_name=test_model))
    # print(f"\n--- Probando Ideas con {test_model} ---")
    # print(generate_ideas(test_prompt, model_name=test_model))

if __name__ == '__main__':
    main() 